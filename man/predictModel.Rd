% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/predictModel.R
\name{predictModel}
\alias{predictModel}
\title{Predict model on server site}
\usage{
predictModel(
  connections,
  mod,
  pred_name,
  dat_name = "D",
  predict_fun = "predict(mod, newdata = D)",
  repush = FALSE,
  sep = "-",
  check_serialization = TRUE,
  install_if_not_available = TRUE,
  just_return_call = FALSE
)
}
\arguments{
\item{connections}{[DSI::connection] Connection to an OPAL server.}

\item{mod}{[arbitrary] R object containing a model which is used for predictions on the server side.}

\item{pred_name}{[character(1L)] Name of the object predictions should be assigned to.}

\item{dat_name}{[character(1L)] Name of the data object on the server.}

\item{predict_fun}{[character(1L)] The prediction function call as string. As placeholder
use 'mod' for the model and 'D' for the data, e.g. `predict(mod, newdata = D)`. This
gives the possibility to call arbitrary predict function like
`predict(mod, newdata = D, type = \"response\")' for a GLM.}

\item{repush}{[logical(1L)] Logical value indicating if the model should again pushed to the server.}

\item{sep}{[character(1L)] Separator used to collapse the binary elements.}

\item{check_serialization}{[logical(1L)] Check if the serialized model can be deserialized}

\item{install_if_not_available}{[logical(1L)] Install package if it is not installed.}

\item{just_return_call}{[logical(1L)] Just return the call and not execute on server (mainly for testing purposes).}
}
\value{
parts required for lm
}
\description{
This function enables to make predictions on the server for any
  model.
}
\author{
Daniel S.
}
